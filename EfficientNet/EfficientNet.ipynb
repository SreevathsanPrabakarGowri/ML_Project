{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline EfficientNet-B0"
      ],
      "metadata": {
        "id": "j_wysvsXhPC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import csv\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:02:36.371424Z",
          "iopub.execute_input": "2025-11-28T17:02:36.372267Z",
          "iopub.status.idle": "2025-11-28T17:02:43.756272Z",
          "shell.execute_reply.started": "2025-11-28T17:02:36.372236Z",
          "shell.execute_reply": "2025-11-28T17:02:43.755288Z"
        },
        "id": "gmIiG_kYhPC6",
        "outputId": "afe77bc5-cd9e-400f-b72c-9ad8a163ff79"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Device: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. CIFAR-10 Dataset (Resize to 128x128)\n",
        "\n",
        "transform_train = T.Compose([\n",
        "    T.Resize((128, 128)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = T.Compose([\n",
        "    T.Resize((128, 128)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train,\n",
        ")\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_test,\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = trainset.classes\n",
        "num_classes = 10"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:02:51.213398Z",
          "iopub.execute_input": "2025-11-28T17:02:51.214213Z",
          "iopub.status.idle": "2025-11-28T17:03:11.018658Z",
          "shell.execute_reply.started": "2025-11-28T17:02:51.214184Z",
          "shell.execute_reply": "2025-11-28T17:03:11.018081Z"
        },
        "id": "W2N4h46ShPDB",
        "outputId": "66d08392-b36c-4adf-bee2-842fe3d7a697"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 170M/170M [00:15<00:00, 11.1MB/s] \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Simple FLOPs Counter (Conv2d + Linear only)\n",
        "\n",
        "def count_flops(model, input_size=(1, 3, 128, 128)):\n",
        "    hooks = []\n",
        "    flops = []\n",
        "\n",
        "    def conv_hook(self, inp, out):\n",
        "        # inp[0]: (B, Cin, H, W)\n",
        "        x = inp[0]\n",
        "        Cin = x.shape[1]\n",
        "        Cout = self.out_channels\n",
        "        kH, kW = self.kernel_size\n",
        "        out_h, out_w = out.shape[2], out.shape[3]\n",
        "        groups = self.groups\n",
        "        # MACs = Cout * (Cin/groups) * kH * kW * out_h * out_w\n",
        "        flops.append(Cout * (Cin // groups) * kH * kW * out_h * out_w)\n",
        "\n",
        "    def linear_hook(self, inp, out):\n",
        "        in_f = inp[0].shape[-1]\n",
        "        out_f = out.shape[-1]\n",
        "        flops.append(in_f * out_f)\n",
        "\n",
        "    for layer in model.modules():\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            hooks.append(layer.register_forward_hook(conv_hook))\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            hooks.append(layer.register_forward_hook(linear_hook))\n",
        "\n",
        "    dummy = torch.randn(*input_size).to(next(model.parameters()).device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        model(dummy)\n",
        "\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    return sum(flops)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:03:17.276735Z",
          "iopub.execute_input": "2025-11-28T17:03:17.277007Z",
          "iopub.status.idle": "2025-11-28T17:03:17.283661Z",
          "shell.execute_reply.started": "2025-11-28T17:03:17.276988Z",
          "shell.execute_reply": "2025-11-28T17:03:17.282998Z"
        },
        "id": "zNYD2k4ohPDE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Build Baseline EfficientNet-B0\n",
        "\n",
        "def build_efficientnet_b0_baseline(num_classes=10):\n",
        "    model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "model_name = \"EfficientNetB0\"\n",
        "model = build_efficientnet_b0_baseline(num_classes=num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:03:32.821592Z",
          "iopub.execute_input": "2025-11-28T17:03:32.822390Z",
          "iopub.status.idle": "2025-11-28T17:03:33.250510Z",
          "shell.execute_reply.started": "2025-11-28T17:03:32.822364Z",
          "shell.execute_reply": "2025-11-28T17:03:33.249706Z"
        },
        "id": "xVEGc2mIhPDG",
        "outputId": "0ee66b21-6f85-4831-b5ee-a39b892cbdd5"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 224MB/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Training & Evaluation Helpers\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "\n",
        "    return running_loss / len(loader), 100.0 * correct / total\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "    acc = 100.0 * correct / total\n",
        "    return acc, np.array(all_labels), np.array(all_preds)\n",
        "\n",
        "def plot_learning_curves(name, train_losses, train_accs, test_accs):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"{name} - Training Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/kaggle/working/{name}_loss_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_accs, label=\"Train Acc\")\n",
        "    plt.plot(epochs, test_accs, label=\"Test Acc\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(f\"{name} - Accuracy Curves\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/kaggle/working/{name}_accuracy_curves.png\")\n",
        "    plt.close()\n",
        "\n",
        "def save_confusion_matrix(name, y_true, y_pred, classes):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, cmap=\"Blues\", cbar=False)\n",
        "    plt.title(f\"{name} - CIFAR-10 Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/kaggle/working/{name}_confusion_matrix.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:03:55.550361Z",
          "iopub.execute_input": "2025-11-28T17:03:55.550691Z",
          "iopub.status.idle": "2025-11-28T17:03:55.560865Z",
          "shell.execute_reply.started": "2025-11-28T17:03:55.550636Z",
          "shell.execute_reply": "2025-11-28T17:03:55.560084Z"
        },
        "id": "5JU7ULr_hPDH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. Training Loop\n",
        "\n",
        "train_losses, train_accs, test_accs = [], [], []\n",
        "train_start = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    t0 = time.time()\n",
        "    loss, train_acc = train_one_epoch(model, trainloader, optimizer, criterion)\n",
        "    test_acc, _, _ = evaluate(model, testloader)\n",
        "    t1 = time.time()\n",
        "\n",
        "    train_losses.append(loss)\n",
        "    train_accs.append(train_acc)\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "    print(f\"[{model_name}] Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Loss={loss:.4f} | TrainAcc={train_acc:.2f}% | \"\n",
        "          f\"TestAcc={test_acc:.2f}% | Time={t1 - t0:.2f}s\")\n",
        "\n",
        "train_end = time.time()\n",
        "total_train_time = train_end - train_start\n",
        "\n",
        "final_train_acc = train_accs[-1]\n",
        "final_test_acc, y_true, y_pred = evaluate(model, testloader)\n",
        "\n",
        "print(f\"\\n[{model_name}] Total training time: {total_train_time:.2f}s \"\n",
        "      f\"({total_train_time/60:.2f} min)\")\n",
        "print(f\"[{model_name}] Final Train Acc: {final_train_acc:.2f}%\")\n",
        "print(f\"[{model_name}] Final Test  Acc: {final_test_acc:.2f}%\")\n",
        "\n",
        "plot_learning_curves(model_name, train_losses, train_accs, test_accs)\n",
        "save_confusion_matrix(model_name, y_true, y_pred, classes)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:04:26.113873Z",
          "iopub.execute_input": "2025-11-28T17:04:26.114148Z",
          "iopub.status.idle": "2025-11-28T17:15:55.794820Z",
          "shell.execute_reply.started": "2025-11-28T17:04:26.114126Z",
          "shell.execute_reply": "2025-11-28T17:15:55.794102Z"
        },
        "id": "WiexCJcWhPDJ",
        "outputId": "b3c86511-fba0-4062-c247-66577346e12a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[EfficientNetB0] Epoch 1/10 | Loss=0.6185 | TrainAcc=81.23% | TestAcc=93.14% | Time=69.49s\n[EfficientNetB0] Epoch 2/10 | Loss=0.1828 | TrainAcc=93.93% | TestAcc=94.84% | Time=68.55s\n[EfficientNetB0] Epoch 3/10 | Loss=0.1166 | TrainAcc=96.16% | TestAcc=95.51% | Time=68.23s\n[EfficientNetB0] Epoch 4/10 | Loss=0.0803 | TrainAcc=97.35% | TestAcc=95.64% | Time=68.48s\n[EfficientNetB0] Epoch 5/10 | Loss=0.0584 | TrainAcc=98.04% | TestAcc=95.67% | Time=68.47s\n[EfficientNetB0] Epoch 6/10 | Loss=0.0451 | TrainAcc=98.52% | TestAcc=95.59% | Time=68.19s\n[EfficientNetB0] Epoch 7/10 | Loss=0.0371 | TrainAcc=98.75% | TestAcc=95.90% | Time=68.74s\n[EfficientNetB0] Epoch 8/10 | Loss=0.0311 | TrainAcc=98.99% | TestAcc=95.73% | Time=68.34s\n[EfficientNetB0] Epoch 9/10 | Loss=0.0266 | TrainAcc=99.12% | TestAcc=95.74% | Time=68.21s\n[EfficientNetB0] Epoch 10/10 | Loss=0.0228 | TrainAcc=99.27% | TestAcc=95.78% | Time=68.19s\n\n[EfficientNetB0] Total training time: 684.90s (11.42 min)\n[EfficientNetB0] Final Train Acc: 99.27%\n[EfficientNetB0] Final Test  Acc: 95.78%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6. FLOPs & Params\n",
        "\n",
        "flops = count_flops(model, input_size=(1, 3, 128, 128))\n",
        "params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f\"[{model_name}] Params: {params}\")\n",
        "print(f\"[{model_name}] FLOPs:  {flops:.3g}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:16:15.349313Z",
          "iopub.execute_input": "2025-11-28T17:16:15.350010Z",
          "iopub.status.idle": "2025-11-28T17:16:15.406426Z",
          "shell.execute_reply.started": "2025-11-28T17:16:15.349977Z",
          "shell.execute_reply": "2025-11-28T17:16:15.405693Z"
        },
        "id": "kXrITQ6lhPDM",
        "outputId": "660346db-0618-4bf2-b88b-78e6e460f477"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[EfficientNetB0] Params: 4020358\n[EfficientNetB0] FLOPs:  1.26e+08\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 7. Inference & Training Runtime (100 runs)\n",
        "\n",
        "dummy_x = torch.randn(1, 3, 128, 128).to(device)\n",
        "\n",
        "# Inference time\n",
        "model.eval()\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(10):\n",
        "        _ = model(dummy_x)\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):\n",
        "        _ = model(dummy_x)\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "infer_ms = (t1 - t0) / 100.0 * 1000.0\n",
        "\n",
        "if device == \"cuda\":\n",
        "    mem_infer_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "else:\n",
        "    mem_infer_mb = 0.0\n",
        "\n",
        "# Training time (single-batch steps)\n",
        "model.train()\n",
        "dummy_label = torch.randint(0, num_classes, (1,), device=device)\n",
        "optimizer_step = optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion_step = nn.CrossEntropyLoss()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "for _ in range(10):\n",
        "    optimizer_step.zero_grad()\n",
        "    out = model(dummy_x)\n",
        "    loss = criterion_step(out, dummy_label)\n",
        "    loss.backward()\n",
        "    optimizer_step.step()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "for _ in range(100):\n",
        "    optimizer_step.zero_grad()\n",
        "    out = model(dummy_x)\n",
        "    loss = criterion_step(out, dummy_label)\n",
        "    loss.backward()\n",
        "    optimizer_step.step()\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "train_ms = (t1 - t0) / 100.0 * 1000.0\n",
        "\n",
        "if device == \"cuda\":\n",
        "    mem_train_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "else:\n",
        "    mem_train_mb = 0.0\n",
        "\n",
        "mem_mb = max(mem_infer_mb, mem_train_mb)\n",
        "\n",
        "print(f\"\\n[{model_name}] Inference time / image: {infer_ms:.3f} ms\")\n",
        "print(f\"[{model_name}] Train step / image: {train_ms:.3f} ms\")\n",
        "print(f\"[{model_name}] Peak GPU memory: {mem_mb:.2f} MB\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:16:44.944804Z",
          "iopub.execute_input": "2025-11-28T17:16:44.945122Z",
          "iopub.status.idle": "2025-11-28T17:16:48.808674Z",
          "shell.execute_reply.started": "2025-11-28T17:16:44.945099Z",
          "shell.execute_reply": "2025-11-28T17:16:48.807957Z"
        },
        "id": "sfGB1CuNhPDO",
        "outputId": "95d21cb0-0dbe-492b-91ea-defa0099e8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n[EfficientNetB0] Inference time / image: 8.088 ms\n[EfficientNetB0] Train step / image: 26.770 ms\n[EfficientNetB0] Peak GPU memory: 100.27 MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 8. Save Model & Metrics CSV\n",
        "\n",
        "torch.save(model.state_dict(),\n",
        "           f\"/kaggle/working/{model_name}_cifar10_128x128.pth\")\n",
        "\n",
        "csv_path = f\"/kaggle/working/{model_name}_metrics.csv\"\n",
        "with open(csv_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\n",
        "        \"Model\", \"Params\", \"FLOPs\",\n",
        "        \"Infer_ms\", \"Train_ms\",\n",
        "        \"Memory_MB\", \"TotalTrainTimeSec\",\n",
        "        \"FinalTrainAcc\", \"FinalTestAcc\"\n",
        "    ])\n",
        "    writer.writerow([\n",
        "        model_name,\n",
        "        params,\n",
        "        flops,\n",
        "        infer_ms,\n",
        "        train_ms,\n",
        "        mem_mb,\n",
        "        total_train_time,\n",
        "        final_train_acc,\n",
        "        final_test_acc,\n",
        "    ])\n",
        "\n",
        "print(f\"\\n[{model_name}] Metrics CSV saved to: {csv_path}\")\n",
        "print(f\"[{model_name}] Done.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:16:53.146989Z",
          "iopub.execute_input": "2025-11-28T17:16:53.147281Z",
          "iopub.status.idle": "2025-11-28T17:16:53.203629Z",
          "shell.execute_reply.started": "2025-11-28T17:16:53.147261Z",
          "shell.execute_reply": "2025-11-28T17:16:53.202826Z"
        },
        "id": "n1jID1oAhPDQ",
        "outputId": "800c79c0-7fdc-4a07-c242-a635eaf5c986"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n[EfficientNetB0] Metrics CSV saved to: /kaggle/working/EfficientNetB0_metrics.csv\n[EfficientNetB0] Done.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Oriented 1D EfficientNet-B0"
      ],
      "metadata": {
        "id": "6SOYXNvMhPDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import csv\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "from torchvision.transforms.functional import rotate\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:17:06.446775Z",
          "iopub.execute_input": "2025-11-28T17:17:06.447493Z",
          "iopub.status.idle": "2025-11-28T17:17:06.452981Z",
          "shell.execute_reply.started": "2025-11-28T17:17:06.447470Z",
          "shell.execute_reply": "2025-11-28T17:17:06.452130Z"
        },
        "id": "tHhJkl4-hPDT",
        "outputId": "aaee092b-4a57-4ec9-c677-10f431e65d8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Device: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. CIFAR-10 Dataset (Resize to 128x128)\n",
        "\n",
        "transform_train = T.Compose([\n",
        "    T.Resize((128, 128)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = T.Compose([\n",
        "    T.Resize((128, 128)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train,\n",
        ")\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_test,\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = trainset.classes\n",
        "num_classes = 10"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:17:18.860363Z",
          "iopub.execute_input": "2025-11-28T17:17:18.861090Z",
          "iopub.status.idle": "2025-11-28T17:17:20.481577Z",
          "shell.execute_reply.started": "2025-11-28T17:17:18.861064Z",
          "shell.execute_reply": "2025-11-28T17:17:20.480951Z"
        },
        "id": "XPe-i_3fhPDU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Simple FLOPs Counter\n",
        "\n",
        "def count_flops(model, input_size=(1, 3, 128, 128)):\n",
        "    hooks = []\n",
        "    flops = []\n",
        "\n",
        "    def conv_hook(self, inp, out):\n",
        "        x = inp[0]\n",
        "        Cin = x.shape[1]\n",
        "        Cout = self.out_channels\n",
        "        kH, kW = self.kernel_size\n",
        "        out_h, out_w = out.shape[2], out.shape[3]\n",
        "        groups = self.groups\n",
        "        flops.append(Cout * (Cin // groups) * kH * kW * out_h * out_w)\n",
        "\n",
        "    def linear_hook(self, inp, out):\n",
        "        in_f = inp[0].shape[-1]\n",
        "        out_f = out.shape[-1]\n",
        "        flops.append(in_f * out_f)\n",
        "\n",
        "    for layer in model.modules():\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            hooks.append(layer.register_forward_hook(conv_hook))\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            hooks.append(layer.register_forward_hook(linear_hook))\n",
        "\n",
        "    dummy = torch.randn(*input_size).to(next(model.parameters()).device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        model(dummy)\n",
        "\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    return sum(flops)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:17:38.048137Z",
          "iopub.execute_input": "2025-11-28T17:17:38.048864Z",
          "iopub.status.idle": "2025-11-28T17:17:38.055188Z",
          "shell.execute_reply.started": "2025-11-28T17:17:38.048838Z",
          "shell.execute_reply": "2025-11-28T17:17:38.054479Z"
        },
        "id": "cQGV8qSzhPDV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Oriented 1D Conv2d\n",
        "\n",
        "class Oriented1DConv2d(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size=7,\n",
        "        num_angles=8,\n",
        "        stride=(1,1),\n",
        "        bias=True,\n",
        "        groups=1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert kernel_size % 2 == 1,\n",
        "        if isinstance(stride, int):\n",
        "            stride = (stride, stride)\n",
        "\n",
        "        self.num_angles = num_angles\n",
        "        self.angles = [i * 180.0 / num_angles for i in range(num_angles)]\n",
        "\n",
        "        pad = kernel_size // 2\n",
        "        # vertical 1D kernel (K x 1), orientation via rotate()\n",
        "        self.conv1d = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=(kernel_size, 1),\n",
        "            stride=stride,\n",
        "            padding=(pad, 0),\n",
        "            bias=bias,\n",
        "            groups=groups,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        for ang in self.angles:\n",
        "            xr = rotate(x, angle=ang, interpolation=InterpolationMode.BILINEAR)\n",
        "            y = self.conv1d(xr)\n",
        "            y = rotate(y, angle=-ang, interpolation=InterpolationMode.BILINEAR)\n",
        "            outs.append(y)\n",
        "        return sum(outs) / self.num_angles\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:18:02.101675Z",
          "iopub.execute_input": "2025-11-28T17:18:02.101975Z",
          "iopub.status.idle": "2025-11-28T17:18:02.108733Z",
          "shell.execute_reply.started": "2025-11-28T17:18:02.101956Z",
          "shell.execute_reply": "2025-11-28T17:18:02.107928Z"
        },
        "id": "iTQ1rs9phPDV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Replace depthwise convs with Oriented1DConv2d\n",
        "\n",
        "def replace_depthwise_with_oriented(module, kernel_size=7, num_angles=8):\n",
        "    for name, child in list(module.named_children()):\n",
        "        if isinstance(child, nn.Conv2d):\n",
        "            if (\n",
        "                child.groups == child.in_channels\n",
        "                and child.kernel_size[0] == child.kernel_size[1]\n",
        "                and child.kernel_size[0] > 1\n",
        "            ):\n",
        "                new_conv = Oriented1DConv2d(\n",
        "                    in_channels=child.in_channels,\n",
        "                    out_channels=child.out_channels,\n",
        "                    kernel_size=kernel_size,\n",
        "                    num_angles=num_angles,\n",
        "                    stride=child.stride,\n",
        "                    bias=(child.bias is not None),\n",
        "                    groups=child.groups,\n",
        "                )\n",
        "                setattr(module, name, new_conv)\n",
        "            else:\n",
        "                replace_depthwise_with_oriented(child, kernel_size, num_angles)\n",
        "        else:\n",
        "            replace_depthwise_with_oriented(child, kernel_size, num_angles)\n",
        "\n",
        "def build_oriented_efficientnet_b0(num_classes=10, kernel_size=7, num_angles=8):\n",
        "    model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "    replace_depthwise_with_oriented(model.features, kernel_size=kernel_size, num_angles=num_angles)\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "model_name = \"OrientedEfficientNetB0\"\n",
        "model = build_oriented_efficientnet_b0(num_classes=num_classes, kernel_size=7, num_angles=8)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "num_epochs = 10\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:18:21.702864Z",
          "iopub.execute_input": "2025-11-28T17:18:21.703154Z",
          "iopub.status.idle": "2025-11-28T17:18:21.853503Z",
          "shell.execute_reply.started": "2025-11-28T17:18:21.703135Z",
          "shell.execute_reply": "2025-11-28T17:18:21.852927Z"
        },
        "id": "vH4BteSPhPDW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. Training & Evaluation Helpers\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "\n",
        "    return running_loss / len(loader), 100.0 * correct / total\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "    acc = 100.0 * correct / total\n",
        "    return acc, np.array(all_labels), np.array(all_preds)\n",
        "\n",
        "def plot_learning_curves(name, train_losses, train_accs, test_accs):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"{name} - Training Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/kaggle/working/{name}_loss_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_accs, label=\"Train Acc\")\n",
        "    plt.plot(epochs, test_accs, label=\"Test Acc\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(f\"{name} - Accuracy Curves\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/kaggle/working/{name}_accuracy_curves.png\")\n",
        "    plt.close()\n",
        "\n",
        "def save_confusion_matrix(name, y_true, y_pred, classes):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, cmap=\"Blues\", cbar=False)\n",
        "    plt.title(f\"{name} - CIFAR-10 Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/kaggle/working/{name}_confusion_matrix.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:18:42.196903Z",
          "iopub.execute_input": "2025-11-28T17:18:42.197194Z",
          "iopub.status.idle": "2025-11-28T17:18:42.207297Z",
          "shell.execute_reply.started": "2025-11-28T17:18:42.197173Z",
          "shell.execute_reply": "2025-11-28T17:18:42.206686Z"
        },
        "id": "7e6l2AN6hPDX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6. Training Loop (10 epochs)\n",
        "\n",
        "train_losses, train_accs, test_accs = [], [], []\n",
        "train_start = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    t0 = time.time()\n",
        "    loss, train_acc = train_one_epoch(model, trainloader, optimizer, criterion)\n",
        "    test_acc, _, _ = evaluate(model, testloader)\n",
        "    t1 = time.time()\n",
        "\n",
        "    train_losses.append(loss)\n",
        "    train_accs.append(train_acc)\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "    print(f\"[{model_name}] Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Loss={loss:.4f} | TrainAcc={train_acc:.2f}% | \"\n",
        "          f\"TestAcc={test_acc:.2f}% | Time={t1 - t0:.2f}s\")\n",
        "\n",
        "train_end = time.time()\n",
        "total_train_time = train_end - train_start\n",
        "\n",
        "final_train_acc = train_accs[-1]\n",
        "final_test_acc, y_true, y_pred = evaluate(model, testloader)\n",
        "\n",
        "print(f\"\\n[{model_name}] Total training time: {total_train_time:.2f}s \"\n",
        "      f\"({total_train_time/60:.2f} min)\")\n",
        "print(f\"[{model_name}] Final Train Acc: {final_train_acc:.2f}%\")\n",
        "print(f\"[{model_name}] Final Test  Acc: {final_test_acc:.2f}%\")\n",
        "\n",
        "plot_learning_curves(model_name, train_losses, train_accs, test_accs)\n",
        "save_confusion_matrix(model_name, y_true, y_pred, classes)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:18:59.457416Z",
          "iopub.execute_input": "2025-11-28T17:18:59.457722Z",
          "iopub.status.idle": "2025-11-28T18:35:19.367140Z",
          "shell.execute_reply.started": "2025-11-28T17:18:59.457701Z",
          "shell.execute_reply": "2025-11-28T18:35:19.366256Z"
        },
        "id": "24RiEoxKhPDY",
        "outputId": "10676138-613d-41df-c122-a9141d787e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[OrientedEfficientNetB0] Epoch 1/10 | Loss=1.6654 | TrainAcc=38.76% | TestAcc=50.62% | Time=455.55s\n[OrientedEfficientNetB0] Epoch 2/10 | Loss=1.2829 | TrainAcc=53.46% | TestAcc=57.87% | Time=455.57s\n[OrientedEfficientNetB0] Epoch 3/10 | Loss=1.1135 | TrainAcc=60.03% | TestAcc=61.80% | Time=455.25s\n[OrientedEfficientNetB0] Epoch 4/10 | Loss=1.0021 | TrainAcc=64.38% | TestAcc=65.20% | Time=454.77s\n[OrientedEfficientNetB0] Epoch 5/10 | Loss=0.9120 | TrainAcc=67.45% | TestAcc=67.76% | Time=455.69s\n[OrientedEfficientNetB0] Epoch 6/10 | Loss=0.8433 | TrainAcc=70.13% | TestAcc=68.90% | Time=455.37s\n[OrientedEfficientNetB0] Epoch 7/10 | Loss=0.7810 | TrainAcc=72.41% | TestAcc=70.00% | Time=455.64s\n[OrientedEfficientNetB0] Epoch 8/10 | Loss=0.7298 | TrainAcc=73.99% | TestAcc=71.27% | Time=454.63s\n[OrientedEfficientNetB0] Epoch 9/10 | Loss=0.6827 | TrainAcc=75.96% | TestAcc=72.27% | Time=455.20s\n[OrientedEfficientNetB0] Epoch 10/10 | Loss=0.6414 | TrainAcc=77.35% | TestAcc=73.10% | Time=454.70s\n\n[OrientedEfficientNetB0] Total training time: 4552.37s (75.87 min)\n[OrientedEfficientNetB0] Final Train Acc: 77.35%\n[OrientedEfficientNetB0] Final Test  Acc: 73.10%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 7. FLOPs & Params\n",
        "\n",
        "flops = count_flops(model, input_size=(1, 3, 128, 128))\n",
        "params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f\"[{model_name}] Params: {params}\")\n",
        "print(f\"[{model_name}] FLOPs:  {flops:.3g}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T18:35:51.093361Z",
          "iopub.execute_input": "2025-11-28T18:35:51.094034Z",
          "iopub.status.idle": "2025-11-28T18:35:51.214381Z",
          "shell.execute_reply.started": "2025-11-28T18:35:51.094000Z",
          "shell.execute_reply": "2025-11-28T18:35:51.213634Z"
        },
        "id": "vBfk_cLhhPDZ",
        "outputId": "24273068-8a4b-4003-811f-218ba0143ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[OrientedEfficientNetB0] Params: 3901062\n[OrientedEfficientNetB0] FLOPs:  1.57e+08\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 8. Inference & Training Runtime\n",
        "\n",
        "dummy_x = torch.randn(1, 3, 128, 128).to(device)\n",
        "\n",
        "# Inference\n",
        "model.eval()\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(10):\n",
        "        _ = model(dummy_x)\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):\n",
        "        _ = model(dummy_x)\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "infer_ms = (t1 - t0) / 100.0 * 1000.0\n",
        "\n",
        "if device == \"cuda\":\n",
        "    mem_infer_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "else:\n",
        "    mem_infer_mb = 0.0\n",
        "\n",
        "# Training\n",
        "model.train()\n",
        "dummy_label = torch.randint(0, num_classes, (1,), device=device)\n",
        "optimizer_step = optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion_step = nn.CrossEntropyLoss()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "for _ in range(10):\n",
        "    optimizer_step.zero_grad()\n",
        "    out = model(dummy_x)\n",
        "    loss = criterion_step(out, dummy_label)\n",
        "    loss.backward()\n",
        "    optimizer_step.step()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "for _ in range(100):\n",
        "    optimizer_step.zero_grad()\n",
        "    out = model(dummy_x)\n",
        "    loss = criterion_step(out, dummy_label)\n",
        "    loss.backward()\n",
        "    optimizer_step.step()\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "train_ms = (t1 - t0) / 100.0 * 1000.0\n",
        "\n",
        "if device == \"cuda\":\n",
        "    mem_train_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "else:\n",
        "    mem_train_mb = 0.0\n",
        "\n",
        "mem_mb = max(mem_infer_mb, mem_train_mb)\n",
        "\n",
        "print(f\"\\n[{model_name}] Inference time / image: {infer_ms:.3f} ms\")\n",
        "print(f\"[{model_name}] Train step   / image: {train_ms:.3f} ms\")\n",
        "print(f\"[{model_name}] Peak GPU memory: {mem_mb:.2f} MB\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T18:35:55.537552Z",
          "iopub.execute_input": "2025-11-28T18:35:55.538292Z",
          "iopub.status.idle": "2025-11-28T18:36:30.669711Z",
          "shell.execute_reply.started": "2025-11-28T18:35:55.538266Z",
          "shell.execute_reply": "2025-11-28T18:36:30.668938Z"
        },
        "id": "x0i87AluhPDa",
        "outputId": "8f287178-584f-4d35-b8ec-0773b45a74a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n[OrientedEfficientNetB0] Inference time / image: 102.514 ms\n[OrientedEfficientNetB0] Train step   / image: 212.608 ms\n[OrientedEfficientNetB0] Peak GPU memory: 183.01 MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 9. Save Model & Metrics CSV\n",
        "\n",
        "torch.save(model.state_dict(),\n",
        "           f\"/kaggle/working/{model_name}_cifar10_128x128.pth\")\n",
        "\n",
        "csv_path = f\"/kaggle/working/{model_name}_metrics.csv\"\n",
        "with open(csv_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\n",
        "        \"Model\", \"Params\", \"FLOPs\",\n",
        "        \"Infer_ms\", \"Train_ms\",\n",
        "        \"Memory_MB\", \"TotalTrainTimeSec\",\n",
        "        \"FinalTrainAcc\", \"FinalTestAcc\"\n",
        "    ])\n",
        "    writer.writerow([\n",
        "        model_name,\n",
        "        params,\n",
        "        flops,\n",
        "        infer_ms,\n",
        "        train_ms,\n",
        "        mem_mb,\n",
        "        total_train_time,\n",
        "        final_train_acc,\n",
        "        final_test_acc,\n",
        "    ])\n",
        "\n",
        "print(f\"\\n[{model_name}] Metrics CSV saved to: {csv_path}\")\n",
        "print(f\"[{model_name}] Done.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T18:36:36.943962Z",
          "iopub.execute_input": "2025-11-28T18:36:36.944446Z",
          "iopub.status.idle": "2025-11-28T18:36:36.999231Z",
          "shell.execute_reply.started": "2025-11-28T18:36:36.944422Z",
          "shell.execute_reply": "2025-11-28T18:36:36.998521Z"
        },
        "id": "CyytJHNQhPDb",
        "outputId": "5e94f002-4e21-440c-f51d-4a955a5c134d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n[OrientedEfficientNetB0] Metrics CSV saved to: /kaggle/working/OrientedEfficientNetB0_metrics.csv\n[OrientedEfficientNetB0] Done.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare both the models"
      ],
      "metadata": {
        "id": "IH6gbzZchPDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# 1. Load Metrics from Both Models\n",
        "\n",
        "\n",
        "baseline_csv = \"/kaggle/working/EfficientNetB0_metrics.csv\"\n",
        "oriented_csv = \"/kaggle/working/OrientedEfficientNetB0_metrics.csv\"\n",
        "\n",
        "df_base = pd.read_csv(baseline_csv)\n",
        "df_ori = pd.read_csv(oriented_csv)\n",
        "\n",
        "df_base[\"Type\"] = \"Baseline\"\n",
        "df_ori[\"Type\"] = \"Oriented\"\n",
        "\n",
        "# Combine\n",
        "df = pd.concat([df_base, df_ori], ignore_index=True)\n",
        "\n",
        "print(\"\\n===== FULL METRICS TABLE =====\")\n",
        "display(df)\n",
        "\n",
        "\n",
        "# 2. Extract Rows for Comparison\n",
        "\n",
        "b = df[df[\"Type\"] == \"Baseline\"].iloc[0]\n",
        "o = df[df[\"Type\"] == \"Oriented\"].iloc[0]\n",
        "\n",
        "\n",
        "# 3. Compute Ratios\n",
        "\n",
        "flo_ratio = o[\"FLOPs\"] / b[\"FLOPs\"]\n",
        "infer_ratio = o[\"Infer_ms\"] / b[\"Infer_ms\"]\n",
        "train_ratio = o[\"Train_ms\"] / b[\"Train_ms\"]\n",
        "memory_ratio = o[\"Memory_MB\"] / b[\"Memory_MB\"]\n",
        "efficiency = infer_ratio / flo_ratio\n",
        "\n",
        "print(\"\\n===== RATIOS (Oriented / Baseline) =====\")\n",
        "print(f\"FLOPs Ratio        : {flo_ratio:.4f}\")\n",
        "print(f\"Inference Ratio    : {infer_ratio:.4f}\")\n",
        "print(f\"Training Ratio     : {train_ratio:.4f}\")\n",
        "print(f\"Memory Ratio       : {memory_ratio:.4f}\")\n",
        "print(f\"Efficiency         : {efficiency:.4f}\")\n",
        "\n",
        "\n",
        "# 4. Save Comparison CSV\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"Metric\": [\n",
        "        \"Params\",\n",
        "        \"FLOPs\",\n",
        "        \"Infer_ms\",\n",
        "        \"Train_ms\",\n",
        "        \"Memory_MB\",\n",
        "        \"TotalTrainTimeSec\",\n",
        "        \"FinalTrainAcc\",\n",
        "        \"FinalTestAcc\",\n",
        "        \"FLOPsRatio\",\n",
        "        \"InferenceRatio\",\n",
        "        \"TrainingRatio\",\n",
        "        \"MemoryRatio\",\n",
        "        \"Efficiency\"\n",
        "    ],\n",
        "    \"Baseline\": [\n",
        "        b[\"Params\"],\n",
        "        b[\"FLOPs\"],\n",
        "        b[\"Infer_ms\"],\n",
        "        b[\"Train_ms\"],\n",
        "        b[\"Memory_MB\"],\n",
        "        b[\"TotalTrainTimeSec\"],\n",
        "        b[\"FinalTrainAcc\"],\n",
        "        b[\"FinalTestAcc\"],\n",
        "        \"\",\n",
        "        \"\",\n",
        "        \"\",\n",
        "        \"\",\n",
        "        \"\",\n",
        "    ],\n",
        "    \"Oriented\": [\n",
        "        o[\"Params\"],\n",
        "        o[\"FLOPs\"],\n",
        "        o[\"Infer_ms\"],\n",
        "        o[\"Train_ms\"],\n",
        "        o[\"Memory_MB\"],\n",
        "        o[\"TotalTrainTimeSec\"],\n",
        "        o[\"FinalTrainAcc\"],\n",
        "        o[\"FinalTestAcc\"],\n",
        "        flo_ratio,\n",
        "        infer_ratio,\n",
        "        train_ratio,\n",
        "        memory_ratio,\n",
        "        efficiency,\n",
        "    ],\n",
        "})\n",
        "\n",
        "comp_path = \"/kaggle/working/EfficientNet_Comparison.csv\"\n",
        "comparison.to_csv(comp_path, index=False)\n",
        "\n",
        "print(f\"\\nComparison CSV saved to: {comp_path}\")\n",
        "\n",
        "\n",
        "# 5. Visualization\n",
        "\n",
        "\n",
        "# FLOPs plot\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(data=df, x=\"Type\", y=\"FLOPs\")\n",
        "plt.title(\"FLOPs Comparison\")\n",
        "plt.savefig(\"/kaggle/working/FLOPs_Comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "# Inference time\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(data=df, x=\"Type\", y=\"Infer_ms\")\n",
        "plt.title(\"Inference Time (ms/image)\")\n",
        "plt.savefig(\"/kaggle/working/Inference_Comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "# Training time\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(data=df, x=\"Type\", y=\"Train_ms\")\n",
        "plt.title(\"Training Step Time (ms/image)\")\n",
        "plt.savefig(\"/kaggle/working/TrainTime_Comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "# Speed vs FLOPs\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(df[\"FLOPs\"], df[\"Infer_ms\"], s=100)\n",
        "for i, row in df.iterrows():\n",
        "    plt.text(row[\"FLOPs\"]*1.02, row[\"Infer_ms\"], row[\"Type\"])\n",
        "plt.xlabel(\"FLOPs\")\n",
        "plt.ylabel(\"Inference Time (ms)\")\n",
        "plt.title(\"Speed vs FLOPs\")\n",
        "plt.savefig(\"/kaggle/working/Speed_vs_FLOPs.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nAll comparison plots saved to /kaggle/working/\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T18:40:09.948053Z",
          "iopub.execute_input": "2025-11-28T18:40:09.948347Z",
          "iopub.status.idle": "2025-11-28T18:40:10.335735Z",
          "shell.execute_reply.started": "2025-11-28T18:40:09.948326Z",
          "shell.execute_reply": "2025-11-28T18:40:10.335133Z"
        },
        "id": "zVzlhbdwhPDc",
        "outputId": "861db685-b0b2-4a61-91d6-d83b9111a0aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n===== FULL METRICS TABLE =====\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                    Model   Params      FLOPs    Infer_ms    Train_ms  \\\n0          EfficientNetB0  4020358  125997568    8.088479   26.770236   \n1  OrientedEfficientNetB0  3901062  156898304  102.513957  212.607546   \n\n    Memory_MB  TotalTrainTimeSec  FinalTrainAcc  FinalTestAcc      Type  \n0  100.270996         684.900757         99.268         95.78  Baseline  \n1  183.006836        4552.374904         77.348         73.10  Oriented  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Params</th>\n      <th>FLOPs</th>\n      <th>Infer_ms</th>\n      <th>Train_ms</th>\n      <th>Memory_MB</th>\n      <th>TotalTrainTimeSec</th>\n      <th>FinalTrainAcc</th>\n      <th>FinalTestAcc</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EfficientNetB0</td>\n      <td>4020358</td>\n      <td>125997568</td>\n      <td>8.088479</td>\n      <td>26.770236</td>\n      <td>100.270996</td>\n      <td>684.900757</td>\n      <td>99.268</td>\n      <td>95.78</td>\n      <td>Baseline</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OrientedEfficientNetB0</td>\n      <td>3901062</td>\n      <td>156898304</td>\n      <td>102.513957</td>\n      <td>212.607546</td>\n      <td>183.006836</td>\n      <td>4552.374904</td>\n      <td>77.348</td>\n      <td>73.10</td>\n      <td>Oriented</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n===== RATIOS (Oriented / Baseline) =====\nFLOPs Ratio        : 1.2452\nInference Ratio    : 12.6741\nTraining Ratio     : 7.9419\nMemory Ratio       : 1.8251\nEfficiency         : 10.1779\n\nComparison CSV saved to: /kaggle/working/EfficientNet_Comparison.csv\n\nAll comparison plots saved to /kaggle/working/\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "4VqSN38DhPDd"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}