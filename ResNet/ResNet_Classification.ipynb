{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Normal Resnet-18"
      ],
      "metadata": {
        "id": "i71h-Wc-8PQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ptflops"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T22:31:08.843451Z",
          "iopub.execute_input": "2025-11-27T22:31:08.844249Z",
          "iopub.status.idle": "2025-11-27T22:32:21.894263Z",
          "shell.execute_reply.started": "2025-11-27T22:31:08.844221Z",
          "shell.execute_reply": "2025-11-27T22:32:21.893311Z"
        },
        "id": "LF0_n2AG8PQy",
        "outputId": "2a91758d-aa29-492e-de68-7ddfd381af61"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting ptflops\n  Downloading ptflops-0.7.5-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from ptflops) (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->ptflops)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->ptflops)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->ptflops)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->ptflops)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->ptflops)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->ptflops)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->ptflops)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->ptflops)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->ptflops)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->ptflops)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->ptflops) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->ptflops) (3.0.3)\nDownloading ptflops-0.7.5-py3-none-any.whl (19 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ptflops\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ptflops-0.7.5\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "from ptflops import get_model_complexity_info\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T22:33:37.507125Z",
          "iopub.execute_input": "2025-11-27T22:33:37.507426Z",
          "iopub.status.idle": "2025-11-27T22:33:42.682026Z",
          "shell.execute_reply.started": "2025-11-27T22:33:37.507392Z",
          "shell.execute_reply": "2025-11-27T22:33:42.681176Z"
        },
        "id": "Z8KHhP8n8PQ0",
        "outputId": "a3048202-bdb4-4e6a-a612-97dd31ed2e71"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Device: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. CIFAR-10 DATASET (224x224)\n",
        "\n",
        "transform_train = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train,\n",
        ")\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_test,\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = trainset.classes\n",
        "num_classes = 10"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T22:34:03.805333Z",
          "iopub.execute_input": "2025-11-27T22:34:03.806033Z",
          "iopub.status.idle": "2025-11-27T22:34:05.424192Z",
          "shell.execute_reply.started": "2025-11-27T22:34:03.806008Z",
          "shell.execute_reply": "2025-11-27T22:34:05.423602Z"
        },
        "id": "vPqEwuTo8PQ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. BUILD BASE RESNET-18\n",
        "\n",
        "model = resnet18(\n",
        "    weights=ResNet18_Weights.IMAGENET1K_V1,\n",
        ")\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T22:34:17.790072Z",
          "iopub.execute_input": "2025-11-27T22:34:17.790690Z",
          "iopub.status.idle": "2025-11-27T22:34:18.085556Z",
          "shell.execute_reply.started": "2025-11-27T22:34:17.790664Z",
          "shell.execute_reply": "2025-11-27T22:34:18.084926Z"
        },
        "id": "r81-1MvT8PQ3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. TRAIN & TEST FUNCTIONS\n",
        "\n",
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100.0 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = 100.0 * correct / total\n",
        "    return acc, np.array(all_labels), np.array(all_preds)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T22:34:29.937293Z",
          "iopub.execute_input": "2025-11-27T22:34:29.937568Z",
          "iopub.status.idle": "2025-11-27T22:34:29.944996Z",
          "shell.execute_reply.started": "2025-11-27T22:34:29.937550Z",
          "shell.execute_reply": "2025-11-27T22:34:29.944176Z"
        },
        "id": "6ZzVbnd68PQ4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. TRAINING LOOP\n",
        "\n",
        "train_losses, train_accs, test_accs = [], [], []\n",
        "train_start = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    t0 = time.time()\n",
        "    loss, train_acc = train_one_epoch(model, trainloader)\n",
        "    test_acc, _, _ = evaluate(model, testloader)\n",
        "    t1 = time.time()\n",
        "\n",
        "    train_losses.append(loss)\n",
        "    train_accs.append(train_acc)\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Loss={loss:.4f} | \"\n",
        "          f\"TrainAcc={train_acc:.2f}% | \"\n",
        "          f\"TestAcc={test_acc:.2f}% | \"\n",
        "          f\"EpochTime={t1 - t0:.2f}s\")\n",
        "\n",
        "train_end = time.time()\n",
        "total_train_time = train_end - train_start\n",
        "print(f\"\\nTotal training time: {total_train_time:.2f} seconds \"\n",
        "      f\"({total_train_time/60:.2f} min)\")\n",
        "\n",
        "# Final accuracies\n",
        "final_train_acc = train_accs[-1]\n",
        "final_test_acc, all_labels, all_preds = evaluate(model, testloader)\n",
        "print(f\"Final Train Acc: {final_train_acc:.2f}%\")\n",
        "print(f\"Final Test Acc:  {final_test_acc:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T22:34:45.388648Z",
          "iopub.execute_input": "2025-11-27T22:34:45.389217Z",
          "iopub.status.idle": "2025-11-27T23:06:38.861495Z",
          "shell.execute_reply.started": "2025-11-27T22:34:45.389192Z",
          "shell.execute_reply": "2025-11-27T23:06:38.860663Z"
        },
        "id": "_Quy2A778PQ5",
        "outputId": "4c9057e2-4a20-4745-ad16-14103ae1cf5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/20 | Loss=0.3350 | TrainAcc=89.25% | TestAcc=92.83% | EpochTime=95.49s\nEpoch 2/20 | Loss=0.1197 | TrainAcc=96.20% | TestAcc=93.57% | EpochTime=95.17s\nEpoch 3/20 | Loss=0.0664 | TrainAcc=97.97% | TestAcc=94.38% | EpochTime=95.25s\nEpoch 4/20 | Loss=0.0463 | TrainAcc=98.64% | TestAcc=94.87% | EpochTime=94.68s\nEpoch 5/20 | Loss=0.0314 | TrainAcc=99.04% | TestAcc=94.86% | EpochTime=94.91s\nEpoch 6/20 | Loss=0.0246 | TrainAcc=99.28% | TestAcc=94.60% | EpochTime=95.24s\nEpoch 7/20 | Loss=0.0226 | TrainAcc=99.32% | TestAcc=95.00% | EpochTime=94.76s\nEpoch 8/20 | Loss=0.0201 | TrainAcc=99.35% | TestAcc=94.10% | EpochTime=95.03s\nEpoch 9/20 | Loss=0.0166 | TrainAcc=99.49% | TestAcc=94.73% | EpochTime=97.28s\nEpoch 10/20 | Loss=0.0191 | TrainAcc=99.40% | TestAcc=94.53% | EpochTime=95.18s\nEpoch 11/20 | Loss=0.0176 | TrainAcc=99.44% | TestAcc=94.75% | EpochTime=95.46s\nEpoch 12/20 | Loss=0.0168 | TrainAcc=99.43% | TestAcc=95.14% | EpochTime=95.17s\nEpoch 13/20 | Loss=0.0147 | TrainAcc=99.55% | TestAcc=95.11% | EpochTime=94.99s\nEpoch 14/20 | Loss=0.0145 | TrainAcc=99.50% | TestAcc=94.96% | EpochTime=95.22s\nEpoch 15/20 | Loss=0.0138 | TrainAcc=99.54% | TestAcc=94.72% | EpochTime=95.33s\nEpoch 16/20 | Loss=0.0130 | TrainAcc=99.60% | TestAcc=95.33% | EpochTime=95.21s\nEpoch 17/20 | Loss=0.0155 | TrainAcc=99.48% | TestAcc=95.18% | EpochTime=94.65s\nEpoch 18/20 | Loss=0.0128 | TrainAcc=99.56% | TestAcc=95.32% | EpochTime=94.99s\nEpoch 19/20 | Loss=0.0096 | TrainAcc=99.71% | TestAcc=95.30% | EpochTime=95.00s\nEpoch 20/20 | Loss=0.0129 | TrainAcc=99.56% | TestAcc=95.32% | EpochTime=95.24s\n\nTotal training time: 1904.25 seconds (31.74 min)\nFinal Train Acc: 99.56%\nFinal Test Acc:  95.32%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. FLOPs & PARAMS (ptflops)\n",
        "\n",
        "with torch.no_grad():\n",
        "    macs, params = get_model_complexity_info(\n",
        "        model,\n",
        "        input_res=(3, 224, 224),\n",
        "        as_strings=False,\n",
        "        print_per_layer_stat=False,\n",
        "        verbose=False,\n",
        "    )\n",
        "flops = macs  # treat MACs as FLOPs/MADs\n",
        "\n",
        "print(f\"Params: {int(params)}\")\n",
        "print(f\"FLOPs:  {flops:.3g}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T23:08:20.222568Z",
          "iopub.execute_input": "2025-11-27T23:08:20.223375Z",
          "iopub.status.idle": "2025-11-27T23:08:20.274181Z",
          "shell.execute_reply.started": "2025-11-27T23:08:20.223341Z",
          "shell.execute_reply": "2025-11-27T23:08:20.273506Z"
        },
        "id": "NXwop0Mb8PQ6",
        "outputId": "74fe3c06-52cd-46d0-8637-9498d97bf827"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Params: 11181642\nFLOPs:  1.82e+09\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. INFERENCE & TRAIN RUNTIME\n",
        "\n",
        "dummy_x = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Inference runtime\n",
        "model.eval()\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(10):\n",
        "        _ = model(dummy_x)\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):\n",
        "        _ = model(dummy_x)\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "\n",
        "infer_ms = (t1 - t0) / 100.0 * 1000.0\n",
        "if device == \"cuda\":\n",
        "    mem_infer_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "else:\n",
        "    mem_infer_mb = 0.0\n",
        "\n",
        "# Training runtime (single-batch loop)\n",
        "model.train()\n",
        "dummy_label = torch.randint(0, num_classes, (1,), device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "for _ in range(10):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(dummy_x)\n",
        "    loss = criterion(out, dummy_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "for _ in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(dummy_x)\n",
        "    loss = criterion(out, dummy_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "\n",
        "train_ms = (t1 - t0) / 100.0 * 1000.0\n",
        "if device == \"cuda\":\n",
        "    mem_train_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "else:\n",
        "    mem_train_mb = 0.0\n",
        "\n",
        "mem_mb = max(mem_infer_mb, mem_train_mb)\n",
        "\n",
        "print(f\"\\nInference time per image: {infer_ms:.3f} ms\")\n",
        "print(f\"Train step time per image: {train_ms:.3f} ms\")\n",
        "print(f\"Peak GPU memory: {mem_mb:.2f} MB\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T23:08:26.299260Z",
          "iopub.execute_input": "2025-11-27T23:08:26.299567Z",
          "iopub.status.idle": "2025-11-27T23:08:27.513895Z",
          "shell.execute_reply.started": "2025-11-27T23:08:26.299545Z",
          "shell.execute_reply": "2025-11-27T23:08:27.513229Z"
        },
        "id": "nfvPm4Lm8PQ7",
        "outputId": "a3e9b278-c1ee-405f-b0ad-5a2254e2793a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nInference time per image: 2.232 ms\nTrain step time per image: 7.227 ms\nPeak GPU memory: 214.67 MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. SAVE MODEL & METRICS CSV\n",
        "\n",
        "torch.save(model.state_dict(), \"/kaggle/working/resnet18_cifar10.pth\")\n",
        "\n",
        "csv_path = \"/kaggle/working/resnet18_full_metrics.csv\"\n",
        "with open(csv_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\n",
        "        \"Model\", \"Params\", \"FLOPs\",\n",
        "        \"Infer_ms\", \"Train_ms\",\n",
        "        \"Memory_MB\", \"TotalTrainTimeSec\",\n",
        "        \"FinalTrainAcc\", \"FinalTestAcc\"\n",
        "    ])\n",
        "    writer.writerow([\n",
        "        \"ResNet18\",\n",
        "        int(params),\n",
        "        flops,\n",
        "        infer_ms,\n",
        "        train_ms,\n",
        "        mem_mb,\n",
        "        total_train_time,\n",
        "        final_train_acc,\n",
        "        final_test_acc,\n",
        "    ])\n",
        "\n",
        "print(f\"\\nMetrics CSV saved to: {csv_path}\")\n",
        "print(\"Baseline ResNet18 experiment complete.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T23:08:34.168923Z",
          "iopub.execute_input": "2025-11-27T23:08:34.169670Z",
          "iopub.status.idle": "2025-11-27T23:08:34.243742Z",
          "shell.execute_reply.started": "2025-11-27T23:08:34.169641Z",
          "shell.execute_reply": "2025-11-27T23:08:34.243090Z"
        },
        "id": "EmSUwSr18PQ9",
        "outputId": "2e56ff54-f2bb-4baf-9054-9573582d03a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nMetrics CSV saved to: /kaggle/working/resnet18_full_metrics.csv\nBaseline ResNet18 experiment complete.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Oriented 1D ResNet"
      ],
      "metadata": {
        "id": "DZlqjRo-8PQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import time\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "from torchvision.transforms.functional import rotate\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "from ptflops import get_model_complexity_info\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T23:19:00.627012Z",
          "iopub.execute_input": "2025-11-27T23:19:00.627974Z",
          "iopub.status.idle": "2025-11-27T23:19:00.633727Z",
          "shell.execute_reply.started": "2025-11-27T23:19:00.627943Z",
          "shell.execute_reply": "2025-11-27T23:19:00.633105Z"
        },
        "id": "9q5bZVKN8PQ-",
        "outputId": "335a9e3c-e72d-48f3-c0c0-96d3c678b04a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Device: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. CIFAR-10 DATASET (224x224)\n",
        "\n",
        "transform_train = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train,\n",
        ")\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_test,\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = trainset.classes\n",
        "num_classes = 10"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T23:19:17.223461Z",
          "iopub.execute_input": "2025-11-27T23:19:17.223739Z",
          "iopub.status.idle": "2025-11-27T23:19:18.837462Z",
          "shell.execute_reply.started": "2025-11-27T23:19:17.223722Z",
          "shell.execute_reply": "2025-11-27T23:19:18.836816Z"
        },
        "id": "UFXUPwnt8PQ_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Oriented 1D Conv Layer\n",
        "\n",
        "class Oriented1DConv2d(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size=7,\n",
        "        num_angles=8,\n",
        "        stride=1,\n",
        "        bias=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert kernel_size % 2 == 1\n",
        "        assert stride == 1\n",
        "\n",
        "        self.num_angles = num_angles\n",
        "        self.angles = [i * 180.0 / num_angles for i in range(num_angles)]\n",
        "\n",
        "        pad = kernel_size // 2\n",
        "        self.conv1d = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=(1, kernel_size),\n",
        "            stride=(1, 1),\n",
        "            padding=(0, pad),\n",
        "            bias=bias,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        for ang in self.angles:\n",
        "            xr = rotate(x, angle=ang, interpolation=InterpolationMode.BILINEAR)\n",
        "            y = self.conv1d(xr)\n",
        "            y = rotate(y, angle=-ang, interpolation=InterpolationMode.BILINEAR)\n",
        "            outs.append(y)\n",
        "        return sum(outs) / self.num_angles"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T23:19:31.509840Z",
          "iopub.execute_input": "2025-11-27T23:19:31.510559Z",
          "iopub.status.idle": "2025-11-27T23:19:31.516597Z",
          "shell.execute_reply.started": "2025-11-27T23:19:31.510523Z",
          "shell.execute_reply": "2025-11-27T23:19:31.515704Z"
        },
        "id": "y_5xbsf18PRA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Build Oriented ResNet-18\n",
        "\n",
        "def make_oriented_resnet18(\n",
        "    num_classes=10,\n",
        "    kernel_size=7,\n",
        "    num_angles=8,\n",
        "):\n",
        "    base = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    def replace(layer):\n",
        "        for block in layer:\n",
        "            if hasattr(block, \"conv2\"):\n",
        "                old = block.conv2\n",
        "                if isinstance(old, nn.Conv2d) and old.kernel_size == (3, 3):\n",
        "                    block.conv2 = Oriented1DConv2d(\n",
        "                        in_channels=old.in_channels,\n",
        "                        out_channels=old.out_channels,\n",
        "                        kernel_size=kernel_size,\n",
        "                        num_angles=num_angles,\n",
        "                        stride=1,\n",
        "                        bias=(old.bias is not None),\n",
        "                    )\n",
        "\n",
        "    replace(base.layer1)\n",
        "    replace(base.layer2)\n",
        "    replace(base.layer3)\n",
        "    replace(base.layer4)\n",
        "\n",
        "    base.fc = nn.Linear(base.fc.in_features, num_classes)\n",
        "    return base.to(device)\n",
        "\n",
        "\n",
        "model = make_oriented_resnet18(num_classes=num_classes, kernel_size=7, num_angles=8)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T23:19:43.392003Z",
          "iopub.execute_input": "2025-11-27T23:19:43.392345Z",
          "iopub.status.idle": "2025-11-27T23:19:43.632311Z",
          "shell.execute_reply.started": "2025-11-27T23:19:43.392323Z",
          "shell.execute_reply": "2025-11-27T23:19:43.631695Z"
        },
        "id": "J0mrfKTk8PRB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. TRAIN & TEST FUNCTIONS\n",
        "\n",
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100.0 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = 100.0 * correct / total\n",
        "    return acc, np.array(all_labels), np.array(all_preds)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T23:19:56.106859Z",
          "iopub.execute_input": "2025-11-27T23:19:56.107263Z",
          "iopub.status.idle": "2025-11-27T23:19:56.115298Z",
          "shell.execute_reply.started": "2025-11-27T23:19:56.107241Z",
          "shell.execute_reply": "2025-11-27T23:19:56.114681Z"
        },
        "id": "_Ioabgbu8PRB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. TRAINING LOOP\n",
        "\n",
        "train_losses, train_accs, test_accs = [], [], []\n",
        "train_start = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    t0 = time.time()\n",
        "    loss, train_acc = train_one_epoch(model, trainloader)\n",
        "    test_acc, _, _ = evaluate(model, testloader)\n",
        "    t1 = time.time()\n",
        "\n",
        "    train_losses.append(loss)\n",
        "    train_accs.append(train_acc)\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Loss={loss:.4f} | \"\n",
        "          f\"TrainAcc={train_acc:.2f}% | \"\n",
        "          f\"TestAcc={test_acc:.2f}% | \"\n",
        "          f\"EpochTime={t1 - t0:.2f}s\")\n",
        "\n",
        "train_end = time.time()\n",
        "total_train_time = train_end - train_start\n",
        "print(f\"\\nTotal training time: {total_train_time:.2f} seconds \"\n",
        "      f\"({total_train_time/60:.2f} min)\")\n",
        "\n",
        "final_train_acc = train_accs[-1]\n",
        "final_test_acc, all_labels, all_preds = evaluate(model, testloader)\n",
        "print(f\"Final Train Acc: {final_train_acc:.2f}%\")\n",
        "print(f\"Final Test Acc:  {final_test_acc:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T23:22:58.101281Z",
          "iopub.execute_input": "2025-11-27T23:22:58.102239Z",
          "iopub.status.idle": "2025-11-28T02:15:42.375070Z",
          "shell.execute_reply.started": "2025-11-27T23:22:58.102204Z",
          "shell.execute_reply": "2025-11-28T02:15:42.374318Z"
        },
        "id": "EB1F_0B58PRB",
        "outputId": "967f34b4-d5b4-4a50-c857-54345143fcc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/20 | Loss=1.2242 | TrainAcc=55.89% | TestAcc=59.07% | EpochTime=516.84s\nEpoch 2/20 | Loss=0.7704 | TrainAcc=72.81% | TestAcc=72.08% | EpochTime=516.36s\nEpoch 3/20 | Loss=0.5911 | TrainAcc=79.36% | TestAcc=72.86% | EpochTime=516.01s\nEpoch 4/20 | Loss=0.4732 | TrainAcc=83.53% | TestAcc=80.07% | EpochTime=516.05s\nEpoch 5/20 | Loss=0.3910 | TrainAcc=86.33% | TestAcc=79.90% | EpochTime=516.69s\nEpoch 6/20 | Loss=0.3252 | TrainAcc=88.77% | TestAcc=79.19% | EpochTime=516.29s\nEpoch 7/20 | Loss=0.2730 | TrainAcc=90.49% | TestAcc=81.52% | EpochTime=516.72s\nEpoch 8/20 | Loss=0.2301 | TrainAcc=91.91% | TestAcc=82.16% | EpochTime=516.45s\nEpoch 9/20 | Loss=0.2009 | TrainAcc=92.82% | TestAcc=84.16% | EpochTime=516.66s\nEpoch 10/20 | Loss=0.1625 | TrainAcc=94.34% | TestAcc=82.48% | EpochTime=517.78s\nEpoch 11/20 | Loss=0.1367 | TrainAcc=95.16% | TestAcc=84.58% | EpochTime=517.06s\nEpoch 12/20 | Loss=0.1211 | TrainAcc=95.74% | TestAcc=85.28% | EpochTime=516.80s\nEpoch 13/20 | Loss=0.1064 | TrainAcc=96.27% | TestAcc=86.86% | EpochTime=516.79s\nEpoch 14/20 | Loss=0.0944 | TrainAcc=96.75% | TestAcc=85.69% | EpochTime=516.76s\nEpoch 15/20 | Loss=0.0802 | TrainAcc=97.19% | TestAcc=86.41% | EpochTime=516.67s\nEpoch 16/20 | Loss=0.0743 | TrainAcc=97.41% | TestAcc=85.48% | EpochTime=516.84s\nEpoch 17/20 | Loss=0.0689 | TrainAcc=97.65% | TestAcc=85.58% | EpochTime=516.59s\nEpoch 18/20 | Loss=0.0673 | TrainAcc=97.61% | TestAcc=86.21% | EpochTime=516.66s\nEpoch 19/20 | Loss=0.0552 | TrainAcc=98.14% | TestAcc=84.93% | EpochTime=517.05s\nEpoch 20/20 | Loss=0.0601 | TrainAcc=97.88% | TestAcc=86.75% | EpochTime=516.81s\n\nTotal training time: 10333.89 seconds (172.23 min)\nFinal Train Acc: 97.88%\nFinal Test Acc:  86.75%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. FLOPs & PARAMS\n",
        "\n",
        "with torch.no_grad():\n",
        "    macs, params = get_model_complexity_info(\n",
        "        model,\n",
        "        input_res=(3, 224, 224),\n",
        "        as_strings=False,\n",
        "        print_per_layer_stat=False,\n",
        "        verbose=False,\n",
        "    )\n",
        "flops = macs\n",
        "print(f\"Params: {int(params)}\")\n",
        "print(f\"FLOPs:  {flops:.3g}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:17:48.154960Z",
          "iopub.execute_input": "2025-11-28T02:17:48.155315Z",
          "iopub.status.idle": "2025-11-28T02:17:48.239342Z",
          "shell.execute_reply.started": "2025-11-28T02:17:48.155287Z",
          "shell.execute_reply": "2025-11-28T02:17:48.238629Z"
        },
        "id": "tswccvx-8PRC",
        "outputId": "3ccde06c-da86-4743-fc60-4dd3b7084de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Params: 9789002\nFLOPs:  6.66e+09\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. INFERENCE & TRAIN RUNTIME\n",
        "\n",
        "dummy_x = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Inference runtime\n",
        "model.eval()\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(10):\n",
        "        _ = model(dummy_x)\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):\n",
        "        _ = model(dummy_x)\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "\n",
        "infer_ms = (t1 - t0) / 100.0 * 1000.0\n",
        "if device == \"cuda\":\n",
        "    mem_infer_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "else:\n",
        "    mem_infer_mb = 0.0\n",
        "\n",
        "# Training runtime\n",
        "model.train()\n",
        "dummy_label = torch.randint(0, num_classes, (1,), device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "for _ in range(10):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(dummy_x)\n",
        "    loss = criterion(out, dummy_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "for _ in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(dummy_x)\n",
        "    loss = criterion(out, dummy_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "\n",
        "train_ms = (t1 - t0) / 100.0 * 1000.0\n",
        "if device == \"cuda\":\n",
        "    mem_train_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "else:\n",
        "    mem_train_mb = 0.0\n",
        "\n",
        "mem_mb = max(mem_infer_mb, mem_train_mb)\n",
        "\n",
        "print(f\"\\nInference time per image: {infer_ms:.3f} ms\")\n",
        "print(f\"Train step time per image: {train_ms:.3f} ms\")\n",
        "print(f\"Peak GPU memory: {mem_mb:.2f} MB\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:18:06.703240Z",
          "iopub.execute_input": "2025-11-28T02:18:06.703493Z",
          "iopub.status.idle": "2025-11-28T02:18:25.531624Z",
          "shell.execute_reply.started": "2025-11-28T02:18:06.703477Z",
          "shell.execute_reply": "2025-11-28T02:18:25.530862Z"
        },
        "id": "BBUZfqZ48PRD",
        "outputId": "d6c572e6-5a00-4455-84ea-aead93f81b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nInference time per image: 54.666 ms\nTrain step time per image: 114.454 ms\nPeak GPU memory: 290.07 MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. SAVE MODEL & METRICS CSV\n",
        "\n",
        "torch.save(model.state_dict(), \"/kaggle/working/oriented_resnet18_cifar10.pth\")\n",
        "\n",
        "csv_path = \"/kaggle/working/oriented_resnet18_full_metrics.csv\"\n",
        "with open(csv_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\n",
        "        \"Model\", \"Params\", \"FLOPs\",\n",
        "        \"Infer_ms\", \"Train_ms\",\n",
        "        \"Memory_MB\", \"TotalTrainTimeSec\",\n",
        "        \"FinalTrainAcc\", \"FinalTestAcc\"\n",
        "    ])\n",
        "    writer.writerow([\n",
        "        \"OrientedResNet18\",\n",
        "        int(params),\n",
        "        flops,\n",
        "        infer_ms,\n",
        "        train_ms,\n",
        "        mem_mb,\n",
        "        total_train_time,\n",
        "        final_train_acc,\n",
        "        final_test_acc,\n",
        "    ])\n",
        "\n",
        "print(f\"\\nMetrics CSV saved to: {csv_path}\")\n",
        "print(\"Oriented-ResNet18 experiment complete.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:18:37.395324Z",
          "iopub.execute_input": "2025-11-28T02:18:37.395639Z",
          "iopub.status.idle": "2025-11-28T02:18:37.455334Z",
          "shell.execute_reply.started": "2025-11-28T02:18:37.395611Z",
          "shell.execute_reply": "2025-11-28T02:18:37.454618Z"
        },
        "id": "GO80V6EE8PRD",
        "outputId": "8e9c38e2-aa0b-4813-89a2-5742817f09c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nMetrics CSV saved to: /kaggle/working/oriented_resnet18_full_metrics.csv\nOriented-ResNet18 experiment complete.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare the models"
      ],
      "metadata": {
        "id": "5zyT2ZgL8PRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Load Both Metric CSV Files\n",
        "\n",
        "resnet_csv = \"/kaggle/working/resnet18_full_metrics.csv\"\n",
        "oriented_csv = \"/kaggle/working/oriented_resnet18_full_metrics.csv\"\n",
        "\n",
        "df_res = pd.read_csv(resnet_csv)\n",
        "df_ori = pd.read_csv(oriented_csv)\n",
        "\n",
        "df_res[\"Type\"] = \"ResNet18\"\n",
        "df_ori[\"Type\"] = \"OrientedResNet18\"\n",
        "\n",
        "\n",
        "# Combine Two Tables\n",
        "\n",
        "df = pd.concat([df_res, df_ori], ignore_index=True)\n",
        "\n",
        "print(\"\\n===== Combined Metrics Table =====\\n\")\n",
        "print(df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:20:28.619642Z",
          "iopub.execute_input": "2025-11-28T02:20:28.619966Z",
          "iopub.status.idle": "2025-11-28T02:20:28.661348Z",
          "shell.execute_reply.started": "2025-11-28T02:20:28.619944Z",
          "shell.execute_reply": "2025-11-28T02:20:28.660555Z"
        },
        "id": "oV3t-cdE8PRE",
        "outputId": "d81ce9ce-4a3d-4831-9937-7695e526344c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n===== Combined Metrics Table =====\n\n              Model    Params       FLOPs   Infer_ms    Train_ms   Memory_MB  \\\n0          ResNet18  11181642  1824805898   2.231948    7.227046  214.671875   \n1  OrientedResNet18   9789002  6655346634  54.666362  114.453979  290.074219   \n\n   TotalTrainTimeSec  FinalTrainAcc  FinalTestAcc              Type  \n0        1904.253412         99.562         95.32          ResNet18  \n1       10333.889185         97.882         86.75  OrientedResNet18  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Ratios\n",
        "\n",
        "baseline = df[df[\"Model\"] == \"ResNet18\"].iloc[0]\n",
        "oriented = df[df[\"Model\"] == \"OrientedResNet18\"].iloc[0]\n",
        "\n",
        "InferenceRatio = oriented[\"Infer_ms\"] / baseline[\"Infer_ms\"]\n",
        "TrainRatio = oriented[\"Train_ms\"] / baseline[\"Train_ms\"]\n",
        "FLOPsRatio = oriented[\"FLOPs\"] / baseline[\"FLOPs\"]\n",
        "MemoryRatio = oriented[\"Memory_MB\"] / baseline[\"Memory_MB\"]\n",
        "Efficiency = InferenceRatio / FLOPsRatio\n",
        "\n",
        "print(\"\\n===== RATIOS (Oriented / Baseline) =====\")\n",
        "print(f\"Inference Runtime Ratio: {InferenceRatio:.4f}\")\n",
        "print(f\"Training Runtime Ratio : {TrainRatio:.4f}\")\n",
        "print(f\"FLOPs Ratio           : {FLOPsRatio:.4f}\")\n",
        "print(f\"Memory Ratio          : {MemoryRatio:.4f}\")\n",
        "print(f\"Efficiency            : {Efficiency:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:21:04.164014Z",
          "iopub.execute_input": "2025-11-28T02:21:04.164325Z",
          "iopub.status.idle": "2025-11-28T02:21:04.175457Z",
          "shell.execute_reply.started": "2025-11-28T02:21:04.164304Z",
          "shell.execute_reply": "2025-11-28T02:21:04.174546Z"
        },
        "id": "ObB7ZNDO8PRE",
        "outputId": "67a73aa3-942c-4d29-8dfc-3ef0f8d4d8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n===== RATIOS (Oriented / Baseline) =====\nInference Runtime Ratio: 24.4927\nTraining Runtime Ratio : 15.8369\nFLOPs Ratio           : 3.6472\nMemory Ratio          : 1.3512\nEfficiency            : 6.7156\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save comparison CSV\n",
        "\n",
        "comparison_csv_path = \"/kaggle/working/model_comparison.csv\"\n",
        "\n",
        "df_compare = pd.DataFrame({\n",
        "    \"Metric\": [\n",
        "        \"Params\", \"FLOPs\", \"Inference(ms)\", \"Training(ms)\",\n",
        "        \"Memory_MB\", \"Efficiency\", \"InferenceRatio\", \"FLOPsRatio\"\n",
        "    ],\n",
        "    \"ResNet18\": [\n",
        "        baseline[\"Params\"], baseline[\"FLOPs\"], baseline[\"Infer_ms\"],\n",
        "        baseline[\"Train_ms\"], baseline[\"Memory_MB\"], None, None, None\n",
        "    ],\n",
        "    \"OrientedResNet18\": [\n",
        "        oriented[\"Params\"], oriented[\"FLOPs\"], oriented[\"Infer_ms\"],\n",
        "        oriented[\"Train_ms\"], oriented[\"Memory_MB\"], Efficiency,\n",
        "        InferenceRatio, FLOPsRatio\n",
        "    ]\n",
        "})\n",
        "\n",
        "df_compare.to_csv(comparison_csv_path, index=False)\n",
        "print(f\"\\nComparison CSV saved to: {comparison_csv_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:21:32.093589Z",
          "iopub.execute_input": "2025-11-28T02:21:32.094301Z",
          "iopub.status.idle": "2025-11-28T02:21:32.105165Z",
          "shell.execute_reply.started": "2025-11-28T02:21:32.094277Z",
          "shell.execute_reply": "2025-11-28T02:21:32.104459Z"
        },
        "id": "uKHuVQ9Y8PRF",
        "outputId": "45d97ac0-2c25-4823-963e-5fb37219d793"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nComparison CSV saved to: /kaggle/working/model_comparison.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization of the metrics"
      ],
      "metadata": {
        "id": "_ZGHLQXU8PRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FLOPs Comparison\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=\"Type\", y=\"FLOPs\", data=df)\n",
        "plt.title(\"FLOPs Comparison\")\n",
        "plt.savefig(\"/kaggle/working/flops_comparison.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:22:14.945370Z",
          "iopub.execute_input": "2025-11-28T02:22:14.945934Z",
          "iopub.status.idle": "2025-11-28T02:22:15.144414Z",
          "shell.execute_reply.started": "2025-11-28T02:22:14.945909Z",
          "shell.execute_reply": "2025-11-28T02:22:15.143779Z"
        },
        "id": "aXDxM84G8PRF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference Time Comparison\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=\"Type\", y=\"Infer_ms\", data=df)\n",
        "plt.title(\"Inference Time (ms) Comparison\")\n",
        "plt.savefig(\"/kaggle/working/inference_time_comparison.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:22:46.691945Z",
          "iopub.execute_input": "2025-11-28T02:22:46.692246Z",
          "iopub.status.idle": "2025-11-28T02:22:46.777399Z",
          "shell.execute_reply.started": "2025-11-28T02:22:46.692226Z",
          "shell.execute_reply": "2025-11-28T02:22:46.776555Z"
        },
        "id": "uokqh2bK8PRG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Time Comparison\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=\"Type\", y=\"Train_ms\", data=df)\n",
        "plt.title(\"Training Time (ms) Comparison\")\n",
        "plt.savefig(\"/kaggle/working/train_time_comparison.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:22:58.141720Z",
          "iopub.execute_input": "2025-11-28T02:22:58.142454Z",
          "iopub.status.idle": "2025-11-28T02:22:58.231411Z",
          "shell.execute_reply.started": "2025-11-28T02:22:58.142428Z",
          "shell.execute_reply": "2025-11-28T02:22:58.230565Z"
        },
        "id": "I9oNhVye8PRG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Speed vs FLOPs Scatter Plot (like paper)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(df[\"FLOPs\"], df[\"Infer_ms\"])\n",
        "for i, row in df.iterrows():\n",
        "    plt.text(row[\"FLOPs\"], row[\"Infer_ms\"], row[\"Type\"])\n",
        "plt.xlabel(\"FLOPs\")\n",
        "plt.ylabel(\"Inference Time (ms)\")\n",
        "plt.title(\"Speed vs FLOPs\")\n",
        "plt.savefig(\"/kaggle/working/speed_vs_flops.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:23:28.860667Z",
          "iopub.execute_input": "2025-11-28T02:23:28.860966Z",
          "iopub.status.idle": "2025-11-28T02:23:28.982753Z",
          "shell.execute_reply.started": "2025-11-28T02:23:28.860943Z",
          "shell.execute_reply": "2025-11-28T02:23:28.982152Z"
        },
        "id": "wFjHH5f-8PRG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAll comparison plots saved to /kaggle/working/\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T02:23:39.590609Z",
          "iopub.execute_input": "2025-11-28T02:23:39.591311Z",
          "iopub.status.idle": "2025-11-28T02:23:39.595328Z",
          "shell.execute_reply.started": "2025-11-28T02:23:39.591287Z",
          "shell.execute_reply": "2025-11-28T02:23:39.594531Z"
        },
        "id": "v67LTPkO8PRG",
        "outputId": "bc2dba72-6262-435c-e447-5bf266f41307"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nAll comparison plots saved to /kaggle/working/\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "tCaB6vGx8PRH"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}