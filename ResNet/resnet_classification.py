# -*- coding: utf-8 -*-
"""ResNet_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V-osbD12Ay4pbMCWE1fvNWbyAQJtcXEY

# Normal Resnet-18
"""

!pip install ptflops

import time
import csv
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as T
from torch.utils.data import DataLoader
from torchvision.models import resnet18, ResNet18_Weights

from ptflops import get_model_complexity_info
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Device:", device)

# 1. CIFAR-10 DATASET (224x224)

transform_train = T.Compose([
    T.Resize((224, 224)),
    T.RandomHorizontalFlip(),
    T.ToTensor(),
])

transform_test = T.Compose([
    T.Resize((224, 224)),
    T.ToTensor(),
])

trainset = torchvision.datasets.CIFAR10(
    root="./data",
    train=True,
    download=True,
    transform=transform_train,
)
testset = torchvision.datasets.CIFAR10(
    root="./data",
    train=False,
    download=True,
    transform=transform_test,
)

trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)
testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)

classes = trainset.classes
num_classes = 10

# 2. BUILD BASE RESNET-18

model = resnet18(
    weights=ResNet18_Weights.IMAGENET1K_V1,
)

model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

num_epochs = 20

# 3. TRAIN & TEST FUNCTIONS

def train_one_epoch(model, loader):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for imgs, labels in loader:
        imgs, labels = imgs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, preds = outputs.max(1)
        total += labels.size(0)
        correct += preds.eq(labels).sum().item()

    epoch_loss = running_loss / len(loader)
    epoch_acc = 100.0 * correct / total
    return epoch_loss, epoch_acc


def evaluate(model, loader):
    model.eval()
    correct = 0
    total = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            _, preds = outputs.max(1)
            total += labels.size(0)
            correct += preds.eq(labels).sum().item()
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    acc = 100.0 * correct / total
    return acc, np.array(all_labels), np.array(all_preds)

# 4. TRAINING LOOP

train_losses, train_accs, test_accs = [], [], []
train_start = time.time()

for epoch in range(num_epochs):
    t0 = time.time()
    loss, train_acc = train_one_epoch(model, trainloader)
    test_acc, _, _ = evaluate(model, testloader)
    t1 = time.time()

    train_losses.append(loss)
    train_accs.append(train_acc)
    test_accs.append(test_acc)

    print(f"Epoch {epoch+1}/{num_epochs} | "
          f"Loss={loss:.4f} | "
          f"TrainAcc={train_acc:.2f}% | "
          f"TestAcc={test_acc:.2f}% | "
          f"EpochTime={t1 - t0:.2f}s")

train_end = time.time()
total_train_time = train_end - train_start
print(f"\nTotal training time: {total_train_time:.2f} seconds "
      f"({total_train_time/60:.2f} min)")

# Final accuracies
final_train_acc = train_accs[-1]
final_test_acc, all_labels, all_preds = evaluate(model, testloader)
print(f"Final Train Acc: {final_train_acc:.2f}%")
print(f"Final Test Acc:  {final_test_acc:.2f}%")

# 6. FLOPs & PARAMS (ptflops)

with torch.no_grad():
    macs, params = get_model_complexity_info(
        model,
        input_res=(3, 224, 224),
        as_strings=False,
        print_per_layer_stat=False,
        verbose=False,
    )
flops = macs  # treat MACs as FLOPs/MADs

print(f"Params: {int(params)}")
print(f"FLOPs:  {flops:.3g}")

# 7. INFERENCE & TRAIN RUNTIME

dummy_x = torch.randn(1, 3, 224, 224).to(device)

# Inference runtime
model.eval()
if device == "cuda":
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    torch.cuda.synchronize()

with torch.no_grad():
    for _ in range(10):
        _ = model(dummy_x)

if device == "cuda":
    torch.cuda.synchronize()
t0 = time.time()
with torch.no_grad():
    for _ in range(100):
        _ = model(dummy_x)
if device == "cuda":
    torch.cuda.synchronize()
t1 = time.time()

infer_ms = (t1 - t0) / 100.0 * 1000.0
if device == "cuda":
    mem_infer_mb = torch.cuda.max_memory_allocated() / (1024**2)
else:
    mem_infer_mb = 0.0

# Training runtime (single-batch loop)
model.train()
dummy_label = torch.randint(0, num_classes, (1,), device=device)
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()

if device == "cuda":
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    torch.cuda.synchronize()

for _ in range(10):
    optimizer.zero_grad()
    out = model(dummy_x)
    loss = criterion(out, dummy_label)
    loss.backward()
    optimizer.step()

if device == "cuda":
    torch.cuda.synchronize()
t0 = time.time()
for _ in range(100):
    optimizer.zero_grad()
    out = model(dummy_x)
    loss = criterion(out, dummy_label)
    loss.backward()
    optimizer.step()
if device == "cuda":
    torch.cuda.synchronize()
t1 = time.time()

train_ms = (t1 - t0) / 100.0 * 1000.0
if device == "cuda":
    mem_train_mb = torch.cuda.max_memory_allocated() / (1024**2)
else:
    mem_train_mb = 0.0

mem_mb = max(mem_infer_mb, mem_train_mb)

print(f"\nInference time per image: {infer_ms:.3f} ms")
print(f"Train step time per image: {train_ms:.3f} ms")
print(f"Peak GPU memory: {mem_mb:.2f} MB")

# 8. SAVE MODEL & METRICS CSV

torch.save(model.state_dict(), "/kaggle/working/resnet18_cifar10.pth")

csv_path = "/kaggle/working/resnet18_full_metrics.csv"
with open(csv_path, "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow([
        "Model", "Params", "FLOPs",
        "Infer_ms", "Train_ms",
        "Memory_MB", "TotalTrainTimeSec",
        "FinalTrainAcc", "FinalTestAcc"
    ])
    writer.writerow([
        "ResNet18",
        int(params),
        flops,
        infer_ms,
        train_ms,
        mem_mb,
        total_train_time,
        final_train_acc,
        final_test_acc,
    ])

print(f"\nMetrics CSV saved to: {csv_path}")
print("Baseline ResNet18 experiment complete.")

"""# Oriented 1D ResNet"""

# import required libraries
import time
import csv
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as T
from torch.utils.data import DataLoader
from torchvision.models import resnet18, ResNet18_Weights

from torchvision.transforms.functional import rotate
from torchvision.transforms import InterpolationMode

from ptflops import get_model_complexity_info
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Device:", device)

# 1. CIFAR-10 DATASET (224x224)

transform_train = T.Compose([
    T.Resize((224, 224)),
    T.RandomHorizontalFlip(),
    T.ToTensor(),
])

transform_test = T.Compose([
    T.Resize((224, 224)),
    T.ToTensor(),
])

trainset = torchvision.datasets.CIFAR10(
    root="./data",
    train=True,
    download=True,
    transform=transform_train,
)
testset = torchvision.datasets.CIFAR10(
    root="./data",
    train=False,
    download=True,
    transform=transform_test,
)

trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)
testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)

classes = trainset.classes
num_classes = 10

# 2. Oriented 1D Conv Layer

class Oriented1DConv2d(nn.Module):
    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size=7,
        num_angles=8,
        stride=1,
        bias=True,
    ):
        super().__init__()
        assert kernel_size % 2 == 1
        assert stride == 1

        self.num_angles = num_angles
        self.angles = [i * 180.0 / num_angles for i in range(num_angles)]

        pad = kernel_size // 2
        self.conv1d = nn.Conv2d(
            in_channels,
            out_channels,
            kernel_size=(1, kernel_size),
            stride=(1, 1),
            padding=(0, pad),
            bias=bias,
        )

    def forward(self, x):
        outs = []
        for ang in self.angles:
            xr = rotate(x, angle=ang, interpolation=InterpolationMode.BILINEAR)
            y = self.conv1d(xr)
            y = rotate(y, angle=-ang, interpolation=InterpolationMode.BILINEAR)
            outs.append(y)
        return sum(outs) / self.num_angles

# 3. Build Oriented ResNet-18

def make_oriented_resnet18(
    num_classes=10,
    kernel_size=7,
    num_angles=8,
):
    base = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)

    def replace(layer):
        for block in layer:
            if hasattr(block, "conv2"):
                old = block.conv2
                if isinstance(old, nn.Conv2d) and old.kernel_size == (3, 3):
                    block.conv2 = Oriented1DConv2d(
                        in_channels=old.in_channels,
                        out_channels=old.out_channels,
                        kernel_size=kernel_size,
                        num_angles=num_angles,
                        stride=1,
                        bias=(old.bias is not None),
                    )

    replace(base.layer1)
    replace(base.layer2)
    replace(base.layer3)
    replace(base.layer4)

    base.fc = nn.Linear(base.fc.in_features, num_classes)
    return base.to(device)


model = make_oriented_resnet18(num_classes=num_classes, kernel_size=7, num_angles=8)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

num_epochs = 20

# 4. TRAIN & TEST FUNCTIONS

def train_one_epoch(model, loader):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for imgs, labels in loader:
        imgs, labels = imgs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, preds = outputs.max(1)
        total += labels.size(0)
        correct += preds.eq(labels).sum().item()

    epoch_loss = running_loss / len(loader)
    epoch_acc = 100.0 * correct / total
    return epoch_loss, epoch_acc


def evaluate(model, loader):
    model.eval()
    correct = 0
    total = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            _, preds = outputs.max(1)
            total += labels.size(0)
            correct += preds.eq(labels).sum().item()
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    acc = 100.0 * correct / total
    return acc, np.array(all_labels), np.array(all_preds)

# 5. TRAINING LOOP

train_losses, train_accs, test_accs = [], [], []
train_start = time.time()

for epoch in range(num_epochs):
    t0 = time.time()
    loss, train_acc = train_one_epoch(model, trainloader)
    test_acc, _, _ = evaluate(model, testloader)
    t1 = time.time()

    train_losses.append(loss)
    train_accs.append(train_acc)
    test_accs.append(test_acc)

    print(f"Epoch {epoch+1}/{num_epochs} | "
          f"Loss={loss:.4f} | "
          f"TrainAcc={train_acc:.2f}% | "
          f"TestAcc={test_acc:.2f}% | "
          f"EpochTime={t1 - t0:.2f}s")

train_end = time.time()
total_train_time = train_end - train_start
print(f"\nTotal training time: {total_train_time:.2f} seconds "
      f"({total_train_time/60:.2f} min)")

final_train_acc = train_accs[-1]
final_test_acc, all_labels, all_preds = evaluate(model, testloader)
print(f"Final Train Acc: {final_train_acc:.2f}%")
print(f"Final Test Acc:  {final_test_acc:.2f}%")

# 7. FLOPs & PARAMS

with torch.no_grad():
    macs, params = get_model_complexity_info(
        model,
        input_res=(3, 224, 224),
        as_strings=False,
        print_per_layer_stat=False,
        verbose=False,
    )
flops = macs
print(f"Params: {int(params)}")
print(f"FLOPs:  {flops:.3g}")

# 8. INFERENCE & TRAIN RUNTIME

dummy_x = torch.randn(1, 3, 224, 224).to(device)

# Inference runtime
model.eval()
if device == "cuda":
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    torch.cuda.synchronize()

with torch.no_grad():
    for _ in range(10):
        _ = model(dummy_x)

if device == "cuda":
    torch.cuda.synchronize()
t0 = time.time()
with torch.no_grad():
    for _ in range(100):
        _ = model(dummy_x)
if device == "cuda":
    torch.cuda.synchronize()
t1 = time.time()

infer_ms = (t1 - t0) / 100.0 * 1000.0
if device == "cuda":
    mem_infer_mb = torch.cuda.max_memory_allocated() / (1024**2)
else:
    mem_infer_mb = 0.0

# Training runtime
model.train()
dummy_label = torch.randint(0, num_classes, (1,), device=device)
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()

if device == "cuda":
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    torch.cuda.synchronize()

for _ in range(10):
    optimizer.zero_grad()
    out = model(dummy_x)
    loss = criterion(out, dummy_label)
    loss.backward()
    optimizer.step()

if device == "cuda":
    torch.cuda.synchronize()
t0 = time.time()
for _ in range(100):
    optimizer.zero_grad()
    out = model(dummy_x)
    loss = criterion(out, dummy_label)
    loss.backward()
    optimizer.step()
if device == "cuda":
    torch.cuda.synchronize()
t1 = time.time()

train_ms = (t1 - t0) / 100.0 * 1000.0
if device == "cuda":
    mem_train_mb = torch.cuda.max_memory_allocated() / (1024**2)
else:
    mem_train_mb = 0.0

mem_mb = max(mem_infer_mb, mem_train_mb)

print(f"\nInference time per image: {infer_ms:.3f} ms")
print(f"Train step time per image: {train_ms:.3f} ms")
print(f"Peak GPU memory: {mem_mb:.2f} MB")

# 9. SAVE MODEL & METRICS CSV

torch.save(model.state_dict(), "/kaggle/working/oriented_resnet18_cifar10.pth")

csv_path = "/kaggle/working/oriented_resnet18_full_metrics.csv"
with open(csv_path, "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow([
        "Model", "Params", "FLOPs",
        "Infer_ms", "Train_ms",
        "Memory_MB", "TotalTrainTimeSec",
        "FinalTrainAcc", "FinalTestAcc"
    ])
    writer.writerow([
        "OrientedResNet18",
        int(params),
        flops,
        infer_ms,
        train_ms,
        mem_mb,
        total_train_time,
        final_train_acc,
        final_test_acc,
    ])

print(f"\nMetrics CSV saved to: {csv_path}")
print("Oriented-ResNet18 experiment complete.")

"""# Compare the models"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# Load Both Metric CSV Files

resnet_csv = "/kaggle/working/resnet18_full_metrics.csv"
oriented_csv = "/kaggle/working/oriented_resnet18_full_metrics.csv"

df_res = pd.read_csv(resnet_csv)
df_ori = pd.read_csv(oriented_csv)

df_res["Type"] = "ResNet18"
df_ori["Type"] = "OrientedResNet18"


# Combine Two Tables

df = pd.concat([df_res, df_ori], ignore_index=True)

print("\n===== Combined Metrics Table =====\n")
print(df)

# Compute Ratios

baseline = df[df["Model"] == "ResNet18"].iloc[0]
oriented = df[df["Model"] == "OrientedResNet18"].iloc[0]

InferenceRatio = oriented["Infer_ms"] / baseline["Infer_ms"]
TrainRatio = oriented["Train_ms"] / baseline["Train_ms"]
FLOPsRatio = oriented["FLOPs"] / baseline["FLOPs"]
MemoryRatio = oriented["Memory_MB"] / baseline["Memory_MB"]
Efficiency = InferenceRatio / FLOPsRatio

print("\n===== RATIOS (Oriented / Baseline) =====")
print(f"Inference Runtime Ratio: {InferenceRatio:.4f}")
print(f"Training Runtime Ratio : {TrainRatio:.4f}")
print(f"FLOPs Ratio           : {FLOPsRatio:.4f}")
print(f"Memory Ratio          : {MemoryRatio:.4f}")
print(f"Efficiency            : {Efficiency:.4f}")

# Save comparison CSV

comparison_csv_path = "/kaggle/working/model_comparison.csv"

df_compare = pd.DataFrame({
    "Metric": [
        "Params", "FLOPs", "Inference(ms)", "Training(ms)",
        "Memory_MB", "Efficiency", "InferenceRatio", "FLOPsRatio"
    ],
    "ResNet18": [
        baseline["Params"], baseline["FLOPs"], baseline["Infer_ms"],
        baseline["Train_ms"], baseline["Memory_MB"], None, None, None
    ],
    "OrientedResNet18": [
        oriented["Params"], oriented["FLOPs"], oriented["Infer_ms"],
        oriented["Train_ms"], oriented["Memory_MB"], Efficiency,
        InferenceRatio, FLOPsRatio
    ]
})

df_compare.to_csv(comparison_csv_path, index=False)
print(f"\nComparison CSV saved to: {comparison_csv_path}")

"""# Visualization of the metrics"""

# FLOPs Comparison
plt.figure(figsize=(6,4))
sns.barplot(x="Type", y="FLOPs", data=df)
plt.title("FLOPs Comparison")
plt.savefig("/kaggle/working/flops_comparison.png")
plt.close()

# Inference Time Comparison
plt.figure(figsize=(6,4))
sns.barplot(x="Type", y="Infer_ms", data=df)
plt.title("Inference Time (ms) Comparison")
plt.savefig("/kaggle/working/inference_time_comparison.png")
plt.close()

# Training Time Comparison
plt.figure(figsize=(6,4))
sns.barplot(x="Type", y="Train_ms", data=df)
plt.title("Training Time (ms) Comparison")
plt.savefig("/kaggle/working/train_time_comparison.png")
plt.close()

# Speed vs FLOPs Scatter Plot (like paper)
plt.figure(figsize=(6,4))
plt.scatter(df["FLOPs"], df["Infer_ms"])
for i, row in df.iterrows():
    plt.text(row["FLOPs"], row["Infer_ms"], row["Type"])
plt.xlabel("FLOPs")
plt.ylabel("Inference Time (ms)")
plt.title("Speed vs FLOPs")
plt.savefig("/kaggle/working/speed_vs_flops.png")
plt.close()

print("\nAll comparison plots saved to /kaggle/working/")

